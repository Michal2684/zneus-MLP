{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc485a24-10be-4a83-a978-2c4f0e92876c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T10:15:53.941825Z",
     "start_time": "2025-10-23T10:15:53.938790Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Základy neurónových sietí STU FIIT\n",
    "## Credit Risk Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a7f853-9e23-4efa-b13e-420618106776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T15:50:25.603730Z",
     "start_time": "2025-11-07T15:50:21.451907Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda3\\envs\\zneus\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39edf73c-0dc2-40b3-a75c-d5e7ad35e861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: fajermichal48 (fajermichal48-none) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539708ca-b688-429c-91db-11dfeae1ad29",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028678bb-ef47-4e5a-a1c9-07a7e7732905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====SHAPE=====\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbddd9-7953-4c3c-8157-428c77d78481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====HEAD=====\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce0dc1-676c-4969-86e4-6312652cf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====TAIL=====\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2c1e7-ea75-41d8-9122-743ddb08cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====DTYPE=====\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b62e85-9c15-4bab-9614-62ba7f7e8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c21ede-ffc0-4652-a31e-a23950202c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec267f4-0b75-4cbe-b196-2bd31d59b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f6889-9355-4849-9cbe-5bb2d4327e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['number']).columns\n",
    "cat_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "print(\"Numeric columns:\\n\", list(num_cols))\n",
    "print(\"\\nCategorical columns:\\n\", list(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42b6ff-4817-4106-bcc7-432913040f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].hist(figsize=(10,8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206f7b6b-0e76-43ce-9441-fed3ddbf1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[num_cols].corr(), cmap=\"coolwarm\", annot=True, fmt=\".2f\",\n",
    "            vmin=-1, vmax=1, center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(\"Correlation Matrix\", fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb2d104-766a-428b-a456-4b2c087ba4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "for c in cat_cols:\n",
    "    ax = sns.countplot(x=c, data=df)\n",
    "    plt.title(c)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3ce2d-b60d-4e29-86ab-c1a222043d3c",
   "metadata": {},
   "source": [
    "# Data preprocessing and normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453587cb-7172-4564-8c82-cd760cc9dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (1000, 46)\n",
      "Any missing values? 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>age</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>checking_status_'&lt;0'</th>\n",
       "      <th>checking_status_'&gt;=200'</th>\n",
       "      <th>checking_status_'no checking'</th>\n",
       "      <th>credit_history_'critical/other existing credit'</th>\n",
       "      <th>credit_history_'delayed previously'</th>\n",
       "      <th>credit_history_'existing paid'</th>\n",
       "      <th>credit_history_'no credits/all paid'</th>\n",
       "      <th>purpose_'new car'</th>\n",
       "      <th>purpose_'used car'</th>\n",
       "      <th>purpose_business</th>\n",
       "      <th>purpose_education</th>\n",
       "      <th>purpose_furniture/equipment</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_radio/tv</th>\n",
       "      <th>purpose_repairs</th>\n",
       "      <th>purpose_retraining</th>\n",
       "      <th>savings_status_'500&lt;=X&lt;1000'</th>\n",
       "      <th>savings_status_'&lt;100'</th>\n",
       "      <th>savings_status_'&gt;=1000'</th>\n",
       "      <th>savings_status_'no known savings'</th>\n",
       "      <th>employment_'4&lt;=X&lt;7'</th>\n",
       "      <th>employment_'&lt;1'</th>\n",
       "      <th>employment_'&gt;=7'</th>\n",
       "      <th>employment_unemployed</th>\n",
       "      <th>personal_status_'male div/sep'</th>\n",
       "      <th>personal_status_'male mar/wid'</th>\n",
       "      <th>personal_status_'male single'</th>\n",
       "      <th>other_parties_guarantor</th>\n",
       "      <th>other_parties_none</th>\n",
       "      <th>property_magnitude_'no known property'</th>\n",
       "      <th>property_magnitude_'real estate'</th>\n",
       "      <th>property_magnitude_car</th>\n",
       "      <th>other_payment_plans_none</th>\n",
       "      <th>other_payment_plans_stores</th>\n",
       "      <th>housing_own</th>\n",
       "      <th>housing_rent</th>\n",
       "      <th>job_'unemp/unskilled non res'</th>\n",
       "      <th>job_'unskilled resident'</th>\n",
       "      <th>job_skilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  credit_amount  installment_commitment  residence_since  age  \\\n",
       "0         6           1169                       4                4   67   \n",
       "1        48           5951                       2                2   22   \n",
       "2        12           2096                       2                3   49   \n",
       "3        42           7882                       2                4   45   \n",
       "4        24           4870                       3                4   53   \n",
       "\n",
       "   existing_credits  num_dependents  checking_status_'<0'  \\\n",
       "0                 2               1                     1   \n",
       "1                 1               1                     0   \n",
       "2                 1               2                     0   \n",
       "3                 1               2                     1   \n",
       "4                 2               2                     1   \n",
       "\n",
       "   checking_status_'>=200'  checking_status_'no checking'  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              1   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   credit_history_'critical/other existing credit'  \\\n",
       "0                                                1   \n",
       "1                                                0   \n",
       "2                                                1   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   credit_history_'delayed previously'  credit_history_'existing paid'  \\\n",
       "0                                    0                               0   \n",
       "1                                    0                               1   \n",
       "2                                    0                               0   \n",
       "3                                    0                               1   \n",
       "4                                    1                               0   \n",
       "\n",
       "   credit_history_'no credits/all paid'  purpose_'new car'  \\\n",
       "0                                     0                  0   \n",
       "1                                     0                  0   \n",
       "2                                     0                  0   \n",
       "3                                     0                  0   \n",
       "4                                     0                  1   \n",
       "\n",
       "   purpose_'used car'  purpose_business  purpose_education  \\\n",
       "0                   0                 0                  0   \n",
       "1                   0                 0                  0   \n",
       "2                   0                 0                  1   \n",
       "3                   0                 0                  0   \n",
       "4                   0                 0                  0   \n",
       "\n",
       "   purpose_furniture/equipment  purpose_other  purpose_radio/tv  \\\n",
       "0                            0              0                 1   \n",
       "1                            0              0                 1   \n",
       "2                            0              0                 0   \n",
       "3                            1              0                 0   \n",
       "4                            0              0                 0   \n",
       "\n",
       "   purpose_repairs  purpose_retraining  savings_status_'500<=X<1000'  \\\n",
       "0                0                   0                             0   \n",
       "1                0                   0                             0   \n",
       "2                0                   0                             0   \n",
       "3                0                   0                             0   \n",
       "4                0                   0                             0   \n",
       "\n",
       "   savings_status_'<100'  savings_status_'>=1000'  \\\n",
       "0                      0                        0   \n",
       "1                      1                        0   \n",
       "2                      1                        0   \n",
       "3                      1                        0   \n",
       "4                      1                        0   \n",
       "\n",
       "   savings_status_'no known savings'  employment_'4<=X<7'  employment_'<1'  \\\n",
       "0                                  1                    0                0   \n",
       "1                                  0                    0                0   \n",
       "2                                  0                    1                0   \n",
       "3                                  0                    1                0   \n",
       "4                                  0                    0                0   \n",
       "\n",
       "   employment_'>=7'  employment_unemployed  personal_status_'male div/sep'  \\\n",
       "0                 1                      0                               0   \n",
       "1                 0                      0                               0   \n",
       "2                 0                      0                               0   \n",
       "3                 0                      0                               0   \n",
       "4                 0                      0                               0   \n",
       "\n",
       "   personal_status_'male mar/wid'  personal_status_'male single'  \\\n",
       "0                               0                              1   \n",
       "1                               0                              0   \n",
       "2                               0                              1   \n",
       "3                               0                              1   \n",
       "4                               0                              1   \n",
       "\n",
       "   other_parties_guarantor  other_parties_none  \\\n",
       "0                        0                   1   \n",
       "1                        0                   1   \n",
       "2                        0                   1   \n",
       "3                        1                   0   \n",
       "4                        0                   1   \n",
       "\n",
       "   property_magnitude_'no known property'  property_magnitude_'real estate'  \\\n",
       "0                                       0                                 1   \n",
       "1                                       0                                 1   \n",
       "2                                       0                                 1   \n",
       "3                                       0                                 0   \n",
       "4                                       1                                 0   \n",
       "\n",
       "   property_magnitude_car  other_payment_plans_none  \\\n",
       "0                       0                         1   \n",
       "1                       0                         1   \n",
       "2                       0                         1   \n",
       "3                       0                         1   \n",
       "4                       0                         1   \n",
       "\n",
       "   other_payment_plans_stores  housing_own  housing_rent  \\\n",
       "0                           0            1             0   \n",
       "1                           0            1             0   \n",
       "2                           0            1             0   \n",
       "3                           0            0             0   \n",
       "4                           0            0             0   \n",
       "\n",
       "   job_'unemp/unskilled non res'  job_'unskilled resident'  job_skilled  \n",
       "0                              0                         0            1  \n",
       "1                              0                         0            1  \n",
       "2                              0                         1            0  \n",
       "3                              0                         0            1  \n",
       "4                              0                         0            1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "TARGET = \"class\"\n",
    "y_temp = df[TARGET]\n",
    "data = df.drop(columns=[TARGET, \"own_telephone\", \"foreign_worker\"]).copy()\n",
    "\n",
    "cat_cols = data.select_dtypes(include=[\"object\"]).columns\n",
    "data = pd.get_dummies(data, columns=cat_cols, drop_first=True, dtype=int)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_temp)\n",
    "\n",
    "print(\"Final shape:\", data.shape)\n",
    "print(\"Any missing values?\", data.isnull().sum().sum())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc4a38-cffb-4807-ae5b-ed3f603bfbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3480abf3-27b6-4470-8081-3b75ce6a3fab",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e72c0de-77c2-41b4-ba10-0b50d3f56455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (600, 46) y_train: (600,)\n",
      "X_val: (200, 46) y_val: (200,)\n",
      "X_test: (200, 46) y_test: (200,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_train, idx_temp, y_train, y_temp = train_test_split(\n",
    "    df.index, y, test_size=0.4, random_state=11, stratify=y\n",
    ")\n",
    "\n",
    "idx_val, idx_test, y_val, y_test = train_test_split(\n",
    "    idx_temp, y_temp, test_size=0.5, random_state=11, stratify=y_temp\n",
    ")\n",
    "\n",
    "X_train = data.loc[idx_train].reset_index(drop=True)\n",
    "X_val = data.loc[idx_val].reset_index(drop=True)\n",
    "X_test = data.loc[idx_test].reset_index(drop=True)\n",
    "\n",
    "import pandas as pd\n",
    "y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "y_val = pd.Series(y_val).reset_index(drop=True)\n",
    "y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78e0fa-78d5-40a3-93ab-7711bd701398",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d56630a-f6ff-4e15-ac60-14b4f326059a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T16:17:40.290313Z",
     "start_time": "2025-11-02T16:17:40.198680Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118173d-ab2f-4f52-b2c1-6e3474668406",
   "metadata": {},
   "source": [
    "# Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69511ac4-0bca-494d-a9d3-905a019957cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after oversampling:\n",
      "target\n",
      "0    540\n",
      "1    420\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = X_train.copy()\n",
    "train_df[\"target\"] = y_train.values\n",
    "\n",
    "df_major = train_df[train_df[\"target\"] == 1]\n",
    "df_minor = train_df[train_df[\"target\"] == 0]\n",
    "\n",
    "n_samples = len(df_minor) * 2\n",
    "\n",
    "df_minor_up = resample(\n",
    "    df_minor,\n",
    "    replace=True,\n",
    "    n_samples=n_samples,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_balanced = (\n",
    "    pd.concat([df_major, df_minor_up], axis=0)\n",
    "      .sample(frac=1.0, random_state=42)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "X_train_bal = df_balanced.drop(columns=[\"target\"])\n",
    "y_train_bal = df_balanced[\"target\"]\n",
    "\n",
    "print(\"Class distribution after oversampling:\")\n",
    "print(y_train_bal.value_counts())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f57b0d-3ccd-457b-a65c-d067644545e8",
   "metadata": {},
   "source": [
    "# Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fb876d2-6af3-4823-ba8c-1c20cd8006f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config: {'model': {'input_dim': 46, 'output_dim': 1, 'hidden_layers': [64, 32], 'dropout': 0.4, 'use_bn': True}, 'training': {'batch_size': 16, 'lr': 0.0005, 'epochs': 120, 'wandb_project': 'MLP-project', 'early_stop_patience': 25, 'weight_decay': 0.005}}\n"
     ]
    }
   ],
   "source": [
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "model_config = config['model']\n",
    "train_config = config['training']\n",
    "\n",
    "print(\"Using config:\", config)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train_bal.values).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_bal.values.astype(np.float32)) \n",
    "X_val_tensor = torch.from_numpy(X_val.values).float()\n",
    "y_val_tensor = torch.from_numpy(y_val.values.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.values).float()\n",
    "y_test_tensor = torch.from_numpy(y_test.values.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=train_config['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=train_config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ade657-83c8-4466-a9ff-a9ce9ec9614c",
   "metadata": {},
   "source": [
    "# MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "139195b0-7b0c-43d0-9029-3c835858e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MLP, self).__init__()\n",
    "        input_dim = config['input_dim']\n",
    "        hidden_layers = config['hidden_layers']\n",
    "        output_dim = 1 \n",
    "        dropout = config['dropout']\n",
    "        use_bn = config['use_bn']\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcba5e-ab3c-4e99-a71e-83e8b5c74421",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "658d721e-4201-479e-bb94-31c10df9817d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\FIIT\\skola\\33-1\\ZNEUS\\MLP\\wandb\\run-20251107_223827-wt7djff4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fajermichal48-none/MLP-project/runs/wt7djff4' target=\"_blank\">quiet-lion-92</a></strong> to <a href='https://wandb.ai/fajermichal48-none/MLP-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fajermichal48-none/MLP-project' target=\"_blank\">https://wandb.ai/fajermichal48-none/MLP-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fajermichal48-none/MLP-project/runs/wt7djff4' target=\"_blank\">https://wandb.ai/fajermichal48-none/MLP-project/runs/wt7djff4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120: Train Loss 0.7030, Val Loss 0.6991, Val Acc 0.5450\n",
      "Epoch 2/120: Train Loss 0.6353, Val Loss 0.6764, Val Acc 0.6000\n",
      "Epoch 3/120: Train Loss 0.6165, Val Loss 0.6540, Val Acc 0.6150\n",
      "Epoch 4/120: Train Loss 0.5959, Val Loss 0.6445, Val Acc 0.6250\n",
      "Epoch 5/120: Train Loss 0.5566, Val Loss 0.6327, Val Acc 0.6400\n",
      "Epoch 6/120: Train Loss 0.5514, Val Loss 0.6349, Val Acc 0.6500\n",
      "Epoch 7/120: Train Loss 0.5182, Val Loss 0.6521, Val Acc 0.6500\n",
      "Epoch 8/120: Train Loss 0.5106, Val Loss 0.6202, Val Acc 0.6450\n",
      "Epoch 9/120: Train Loss 0.4827, Val Loss 0.6378, Val Acc 0.6500\n",
      "Epoch 10/120: Train Loss 0.4776, Val Loss 0.6385, Val Acc 0.6500\n",
      "Epoch 11/120: Train Loss 0.4832, Val Loss 0.6501, Val Acc 0.6300\n",
      "Epoch 12/120: Train Loss 0.4621, Val Loss 0.6334, Val Acc 0.6250\n",
      "Epoch 13/120: Train Loss 0.4787, Val Loss 0.6456, Val Acc 0.6250\n",
      "Epoch 14/120: Train Loss 0.4441, Val Loss 0.6468, Val Acc 0.6250\n",
      "Epoch 15/120: Train Loss 0.4461, Val Loss 0.6798, Val Acc 0.6150\n",
      "Epoch 16/120: Train Loss 0.4445, Val Loss 0.6385, Val Acc 0.6500\n",
      "Epoch 17/120: Train Loss 0.4180, Val Loss 0.6526, Val Acc 0.6450\n",
      "Epoch 18/120: Train Loss 0.4141, Val Loss 0.6679, Val Acc 0.6650\n",
      "Epoch 19/120: Train Loss 0.3931, Val Loss 0.6438, Val Acc 0.6500\n",
      "Epoch 20/120: Train Loss 0.3933, Val Loss 0.6589, Val Acc 0.6600\n",
      "Epoch 21/120: Train Loss 0.4079, Val Loss 0.6695, Val Acc 0.6550\n",
      "Epoch 22/120: Train Loss 0.3897, Val Loss 0.6474, Val Acc 0.6500\n",
      "Epoch 23/120: Train Loss 0.4044, Val Loss 0.6683, Val Acc 0.6450\n",
      "Epoch 24/120: Train Loss 0.3982, Val Loss 0.6495, Val Acc 0.6450\n",
      "Epoch 25/120: Train Loss 0.3973, Val Loss 0.6594, Val Acc 0.6450\n",
      "Epoch 26/120: Train Loss 0.3796, Val Loss 0.6452, Val Acc 0.6450\n",
      "Epoch 27/120: Train Loss 0.3713, Val Loss 0.6667, Val Acc 0.6400\n",
      "Epoch 28/120: Train Loss 0.3868, Val Loss 0.6639, Val Acc 0.6450\n",
      "Epoch 29/120: Train Loss 0.3866, Val Loss 0.6588, Val Acc 0.6400\n",
      "Epoch 30/120: Train Loss 0.3856, Val Loss 0.6322, Val Acc 0.6550\n",
      "Epoch 31/120: Train Loss 0.3726, Val Loss 0.6639, Val Acc 0.6450\n",
      "Epoch 32/120: Train Loss 0.3614, Val Loss 0.6794, Val Acc 0.6450\n",
      "Epoch 33/120: Train Loss 0.3677, Val Loss 0.6709, Val Acc 0.6500\n",
      "Early stopping at epoch 33\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(model_config).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=train_config['lr'], weight_decay=train_config.get('weight_decay', 0))\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "wandb.init(project=train_config['wandb_project'], config=config)\n",
    "\n",
    "# Early stopping setup\n",
    "patience = train_config.get('early_stop_patience', 15)\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(train_config['epochs']):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device).float() \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in val_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device).float()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            val_loss += loss.item()\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long().cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_labels.extend(batch_y.long().cpu().numpy())  \n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = accuracy_score(val_labels, val_preds)\n",
    "    val_report = classification_report(val_labels, val_preds, output_dict=True, zero_division=0)\n",
    "    \n",
    "    val_table = wandb.Table(columns=[\"\", \"precision\", \"recall\", \"f1-score\", \"support\"])\n",
    "    for cls in ['0', '1']:\n",
    "        if cls in val_report:\n",
    "            val_table.add_data(cls, val_report[cls]['precision'], val_report[cls]['recall'], val_report[cls]['f1-score'], val_report[cls]['support'])\n",
    "    val_table.add_data(\"accuracy\", None, None, val_report['accuracy'], val_report['weighted avg']['support'])\n",
    "    val_table.add_data(\"macro avg\", val_report['macro avg']['precision'], val_report['macro avg']['recall'], val_report['macro avg']['f1-score'], val_report['macro avg']['support'])\n",
    "    val_table.add_data(\"weighted avg\", val_report['weighted avg']['precision'], val_report['weighted avg']['recall'], val_report['weighted avg']['f1-score'], val_report['weighted avg']['support'])\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    wandb.log({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'val_acc': val_acc, 'val_classification_table': val_table})\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{train_config['epochs']}: Train Loss {train_loss:.4f}, Val Loss {val_loss:.4f}, Val Acc {val_acc:.4f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fb74d-d680-4c6c-a6f0-3247e7387abe",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3188ced4-bdf1-4c65-8b7d-822652847f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL TEST CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4583    0.7333    0.5641        60\n",
      "           1     0.8462    0.6286    0.7213       140\n",
      "\n",
      "    accuracy                         0.6600       200\n",
      "   macro avg     0.6522    0.6810    0.6427       200\n",
      "weighted avg     0.7298    0.6600    0.6741       200\n",
      "\n",
      "============================================================\n",
      "Test Accuracy: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▇▇▇▇▇▆▆▆▆▅▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▄▁▃▃▄▂▃▃▆▃▄▅▃▄▅▃▅▄▄▃▅▅▄▂▅▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>test_acc</td><td>0.66</td></tr><tr><td>train_loss</td><td>0.36765</td></tr><tr><td>val_acc</td><td>0.65</td></tr><tr><td>val_loss</td><td>0.67085</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-lion-92</strong> at: <a href='https://wandb.ai/fajermichal48-none/MLP-project/runs/wt7djff4' target=\"_blank\">https://wandb.ai/fajermichal48-none/MLP-project/runs/wt7djff4</a><br> View project at: <a href='https://wandb.ai/fajermichal48-none/MLP-project' target=\"_blank\">https://wandb.ai/fajermichal48-none/MLP-project</a><br>Synced 5 W&B file(s), 34 media file(s), 54 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251107_223827-wt7djff4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device).float()\n",
    "        outputs = model(batch_x)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).long().cpu().numpy()\n",
    "        test_preds.extend(preds)\n",
    "        test_labels.extend(batch_y.long().cpu().numpy())  \n",
    "\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "\n",
    "test_report = classification_report(test_labels, test_preds, output_dict=True, zero_division=0)\n",
    "\n",
    "test_table = wandb.Table(columns=[\"\", \"precision\", \"recall\", \"f1-score\", \"support\"])\n",
    "for cls in ['0', '1']:\n",
    "    if cls in test_report:\n",
    "        test_table.add_data(cls, test_report[cls]['precision'], test_report[cls]['recall'], test_report[cls]['f1-score'], test_report[cls]['support'])\n",
    "test_table.add_data(\"accuracy\", None, None, test_report['accuracy'], test_report['weighted avg']['support'])\n",
    "test_table.add_data(\"macro avg\", test_report['macro avg']['precision'], test_report['macro avg']['recall'], test_report['macro avg']['f1-score'], test_report['macro avg']['support'])\n",
    "test_table.add_data(\"weighted avg\", test_report['weighted avg']['precision'], test_report['weighted avg']['recall'], test_report['weighted avg']['f1-score'], test_report['weighted avg']['support'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST CLASSIFICATION REPORT:\")\n",
    "print(classification_report(test_labels, test_preds, digits=4, zero_division=0))\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "wandb.log({'test_acc': test_acc, 'test_classification_table': test_table})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bd361-c72c-4ba9-ae6f-e42881baaee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
